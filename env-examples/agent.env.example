# ==================================================
# agent.env.example
# Copy to ~/.unsaltedbutter/agent.env
# Loaded after shared.env (overrides shared values if needed)
# Runs on: Mac Mini
# ==================================================

# Mac Studio inference API (LAN address)
STUDIO_URL=http://192.168.1.XXX:8420

# Port this agent listens on for job dispatch from orchestrator
AGENT_PORT=8421

# Path to encryption key (same key as VPS, copied securely)
ENCRYPTION_KEY_PATH=/etc/unsaltedbutter/encryption.keyfile

# Chrome binary path (macOS)
CHROME_PATH=/Applications/Google Chrome.app/Contents/MacOS/Google Chrome

# Operating window (EST timezone)
WINDOW_START_HOUR=6
WINDOW_END_HOUR=20

# Screenshot temp directory (cleaned after each action)
SCREENSHOT_DIR=/tmp/ub-screenshots

# Orchestrator callback URL (LAN address)
ORCHESTRATOR_URL=http://192.168.1.101:8422

# Inference mode: http, coordinate, or mock
INFERENCE_MODE=http

# Behavior profile: normal, cautious, fast
AGENT_PROFILE=normal

# Bind address for agent HTTP server
AGENT_HOST=0.0.0.0

# --- Recording (playbook learn) ---
# VLM API for learn mode (OpenAI-compatible /v1/chat/completions endpoint)
# This is NOT the inference server (port 8420); it's a raw VLM API.
# Examples: https://api.ppq.ai, http://192.168.1.XXX:8080 (local llama.cpp)
VLM_URL=
VLM_KEY=
VLM_MODEL=qwen3-vl-32b
